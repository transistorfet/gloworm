
2023-08-07:
- I moved the OS out of the computie repository and into its own, with the git history preserved
- It will now be known as gloworm, named after the 1980s toy, since my Rust OS was already named Ruxpin after Teddy Ruxpin, so I
  tried to stick to the same theme

2025-01-31:
- the previous time I was working on in this repository was November/December 2023 when I tried to get the monitor and kernel
  compiled in clang, and booted it using Moa.  I ran into the common bug where the MOVEA instruction is assumed to set the flags
  register, but it's the one exception where the flags don't get updated, so a comparison doesn't work.  And it usually affects the
  fputs implementation causing it to print all of memory starting with the welcome message, but never terminating at the null
  character.  I never got around to submitting a bug report
- I've started working on this again since Christmas when I built the k30p-VME, MemBird Woodcock, and CF Card.  I added some commands
  to the monitor to test the VME bus accesses, and test the CF card, and I've since managed to get the kernel booting on the k30p
  and run the network stack

2025-02-01:
- I've been trying to add a config system so that it's easier to conditionally compile things, and linux's config system looks
  simple.  I could try to learn cmake and/or ninja or something, but then anyone building it would have to install those too, and
  they don't look too straightforward for the kind of config I'd like
- Kconfig uses a simple file format for describing config settings and their relations, which generates a single file with all the
  config settings in them.  The config programs are distributed with debian, so they don't have to be included here, and even then,
  the output config file with eg. `CONFIG_M68K=y` is easily human readable and modifiable, it's valid make and bash syntax, can be
  parsed easily.  You do have to make sure the dependecies are satisfied when editing the output by hand, but that's minor.
- A question is whether it's best to try to match the linux config item names, or whether to change some names, like BLK_DEV_RAM
  calling RAMDISK or something instead.  It probably doesn't matter much since I'll eventually write Kconfig files with
  descriptions
- linux seems to not use very many non-bool config items, which makes sense, but I'm thinking of using many more if I can, for
  parameters like device sizes and maybe address offsets for I/O register addresses.  I can't seem to find where linux configures
  those, if it has them configurable at all.  For a lot of systems, they'd all be in the same location, but for me, the ATA device
  on computie is 0x600000 but on computie-vme with the COMET CF Card, it's 0xff800000 or anything in the 0xffxxx000 range I think

2025-02-04:
- there's a lot of issues to fix, but it at least seems to be compiling the kernel and the monitor enough to boot them
- it turns out I was looking in tools/build/Makefile.build in the linux source, but it was scripts/Makefile.build that has the
  more complex build system, which has multiple special variables for targets, and it treats them somewhat specially, so I figured I
  should do the same so I have more control over what gets built how instead of over-generalizing
- I added the userprogs variable with pretty much the same rules to separate out single source file programs from multi-file ones,
  but I haven't tested the multi one yet
- it's building the final step when it shouldn't, and I still need to add the libc makefiles

2025-02-07:
- finally get the new build system implemented.  I had to make some special cases with subdir-y and others to make it build the
  right things, or else it would get confused by too many generic rules.  I still don't have it stripping the binaries for the
  commands yet, but that will come soon

2025-02-08:
- I brought out the k30 and 68k-SMT boards to test the builds on those.  Initially, neither board wanted to boot up.  After a while
  of trying, I finally got the 68k-SMT to run, but it was getting a lot of mistaken characters, not entirely garbage but adacent
  lower case letters, so I guess it was the lower data bits that were getting corrupted occasionally.  It seemed to run ok, printing
  the help text and such, but the characters printed and received were wrong, so maybe something localized to the serial controller
  or FTDI
- the k30-SBC just wouldn't do anything, and then it would print the welcome message but not the prompt, and then it would print the
  prompt but not accept characters, and then it would accept characters but hang when enter was pressed.  Finally I tried a
  different USB port instead of the one on the monitor stand, I used the one connected by the USB3 type-A extension cable and it
  worked
- I was eventually able to get both builds of the kernel and monitor running on them with the ATA drivers using the CONFIG_ATA_BASE
  select as the only difference, so the new build system should work with those boards

2025-02-16 [from retroverse logs]:
- I'm kind of getting sidetracked now, I tried to compile the kernel without -O3 in order to test if the optimizations are causing a
  problem, after reading in the computie logs that I had to add a volatile to strlen in order to get the monitor working previously
  because otherwise it was hanging.  It's very possible a similar thing is happening here with the kernel, so I thought it would be
  quick to check, but then I ran into a problem with undefined fwrite, which is almost certainly related to the wrong object files
  being added to the lib because it compiles both versions of libc.  The only place that fwrite exists that would cause the
  undefineds is in fputs, which is used by fputs in os/ but not in none/
- I compiled it with just the kernel and it worked without errors because it was monitor that had the problem
- trying to load it over serial caused the k30 to reset and run the monitor and start printing out the data instead of reading it
  in.  It was working before I used the unoptimized kernel.  *sigh*  I feel like I had this recently with one of the 3 boards I've
  been playing with
- ok I just checked and it's 100% because the kernel overflows the size that the load script handles (16-bit length) so it loads the
  first ~0x1800 bytes and then boots, but there's more data to send, so I need to keep that in mind now that I have such a big
  kernel.  I could modify the format to use a 4 byte number instead, but I guess I'd have to upgrade the roms on the other boards?
  I'd rather not use a backwards compatible mechanism.

2025-02-17:

- when it works, it switches to the command process and runs that for a while, and before it finishing writing its output, it exits
  and switches to the shell process to handle the exit code, and then to idle again, which switches a couple of times before the
  command's output finishing printing.  It would seem odd that it doesn't have to flush the output before the process exits...
- when it doesn't work, it switches from the command process to the idle process without going through the shell process, and
  the suspend_proc call is made, so it's suspending without exiting.  One of the cases had it switch back to the same command
  process once, before switching to the idle process on the next timer interrupt
- it's calling suspend from the tty write function, which is really just a pass through to the 68681 driver. I don't know why it
  doesn't suspend in 68681 when the only way it could return 0 is if it suspends, but either way, it's not waking up after the
  buffer clears
- it honestly doesn't look hard to add a resume check for tx to the bottom half, or a flush function.  You should make one anyways
  to wait for output to be send before exiting.  I think that comment about never waking up in pipe either was more specifically
  about writing more than the total buffer at once rather than just remaining buffer, or it was before i had the bh stuff. I want
  to clean up the various parts of that

2025-02-18:

- an extra print statement shows it does return 0 like normal from tty_68681_write but it skips the suspend step because O_NONBLOCK
  is set, probably to make the tty driver work correctly, which is why tty_write is the one that suspends.  Either way, it should be
  possible to add a resume
- I added a very quick "if buf not full then call resume_suspended_procs" to the bottom half handler of the tty68681 driver.  At
  first I added one that passes in the tty68681 major device number, and that didn't work because it's the tty driver that suspends,
  but adding a second call that passes in the tty major fixed it up a treat.  It can now print the entire bin listing, suspending at
  least twice during the process, but being woken up both times once the buffer is empty.  So that was the entire problem with the
  listing hanging
- I don't know why I didn't do it earlier.  Maybe I just didn't like doing a double call to resume and wanted to instead put it in
  the tty driver.  It is true that's it's not the most clean, but it's not that unusual since the tty68681 driver is really a
  subdriver of the tty subsystem.  Maybe there's a cleaner way, but at least it doesn't hang anymore

2025-02-22:

- I finally got a refactor done that I had thought would be quick, but ended up taking me 2 days or so.  Even though the standard
  libc and unix are codependent, I kind of had hoped to separate the kernel arch includes from the libc ones, and went back and
  forth a bit, but eventually settled on having src/libc/arch/<arch>/include, and src/kernel/arch/<arch>/include rather than putting
  them together in include/.  I know the existing libc and kernel includes are mixed together, but it's only kernel stuff in
  include/kernel/ and the rest is libc.  Then again I'm still having my doubts
- I also changed the byteorder to_le16, etc functions into endian.h htole16, etc which is posix standard, so the things that use it
  will be more portable to another libc, which might be wanted in some cases
- also using the libc none with other baremetal code easily without needing the kernel

- I also fixed some build issues.  The CFLAGS weren't applying to all downstream directories like I wanted, and I also needed to
  refactor the arch-specific ones so I make a bunch of minor changes.  CFLAGS works now because it doesn't get overwritten in the
  Makefile.defaults file on every decent, and ccflags-y works only for the current directory
- I also added a userprog-ccflags-y, firmware-ccflags-y, and kernel-ccflags-y, which are activated by the respective directory's top
  level Makefile by transfering it to CFLAGS.  The idea is that anything in those categories should get certain general flags that
  are architecture-specific like `-mpcrel` which applies to monitor and boot (firmwares), but not userprogs or the kernel.

2025-02-28:

- I'm working on making it possible to generically register interrupt handlers so that other drivers can be made besides the serial
  driver, and I've had it working for a few days now, in theory, but I'm also re-evaluating how I do contexts, and how I can improve
  it.  I'd like to add the option of doing user mode switching, but there's a limited number of %usp instructions, so I'd have to
  %a6 instead of %a7 to push all the data onto the stack.  There's also the option of not using the stack, although it looks like
  linux is using the stack where on x86 I'm pretty sure it saves the registers in a struct in the process object.
- I'm also not too happy about the double table (the first being the real vector table, and the second being the irq_action table).
  Right now they're the same size, but the second one can at least cut out the exceptions since they're not overridable.  I haven't
  looked closely enough at linux to know how it's storing them, but I want it to be fast, since they're interrupts, so I might still
  stick to a limited table.
- I tried removing the interrupt disable instruction at the entry of the two interrupt handlers I have, and it works when the irq
  handler doesn't have it, but the trap handler does need it.  The 68k only masks the interrupts if an actual hardware interrupt
  occurs, and not on a trap, and I guess without the disable on entry to the trap, it could have another interrupt while the trap
  handler is saving the instructions.  There's only a limited set of trap instructions with specific irqs, so I could get away with
  having the two different types of handlers.  It's maybe splitting hairs over one instruction, but I do still think they'll need to
  be different anyways

2025-03-01:

- I almost have a modified context switcher that can either do what it currently did of always using Supervisor mode, or optionally
  switch to/from User mode, and which in Supervisor-only mode switches to the kernel stack before pushing all the registers, but
  it's not quite working
- I thought I'd try running it on moa last night to "quickly" find the problem, and of course moa isn't working with computie, even
  after changing the memory map to match the VME card.  I can't seem to find where the error is coming from.  It's Emulator(Misc,
  "%d0"), but that error is only created with "Error::new" and all instantiations have a complete error message instead of just the
  register name, so I'm stumped.  The code is such a mess from the time I tried adding emulator-hal.  I really need to pick it up
  and fix it, but I want to work on gloworm first
- ah! the trace function isn't even advancing the instruction, so no wonder it wasn't hitting the fault when tracing in moa

2025-03-02:

- I got thrown off by the fact that I had disabled ATA in the config, but also needed to change the boot stuff as a result.  I need
  to fix how it gets the wrong boot arguments, and also make the boot arguments default use the config value, so it's consistent

2025-03-15:

- I've been trying to rewrite the context switching code for two weeks now, and ...
- I just wandered off and did something else.  It's not that it's hard to do, but I keep just doing other things instead of working
  on it, when I set down to work on it.  Not sure if it's an effect of the medication, or a lack of interesting, or what.  But that
  said, I *do* want to only do it once, and I'm trying to incorporate everything, and read the linux m68k context switch code to
  figure out how it does it
- namely, in arch/m68k: entry.S and include/asm/entry.h
- interestingly enough, it seems to only save the higher numbered registers when it actually switches processes, and otherwise it
  doesn't touch them.  And it can do this because even though it enters the kernel's C code, as long as it doesn't actually change
  states until it's returned all the way up the call stack, out of each re-entry of the kernel, and is finally ready to return from
  the irq or syscall that entered the kernel, the stack will be exactly back to when it entered, and all the extra registers will
  have been restored as part of the C calling convention to preserve their values on the stack.  It will be as if it had just
  entered, and only pushed the scratch registers on the stack.  I'm pretty sure this is what was meant when I read that now all
  interrupts were the "fast interrupt" in Linux, as in it only saves the full context state if it's switching and otherwise only
  saves the minimum (ish) by default

- So, what I want is:
    - to be able to get the interrupt number that occurred (for the handler lookup table)
    - to configurably do what it currently does of only using the supervisor stack, or optionally using user mode
    - save the system call on the stack in a way that doesn't duplicate the values like it currently does
    - don't save all the registers unless a task switch is actually going to happen

- I think that's it.  The questions I still need to answer are: should I always save the systemcall registers, whether in a system
  call or not, or only when in a syscall instead of irq, and how do I know which is which when looking at the stack?
- also, should I keep my syscall register assignments or copy linux which uses %d1-%d5 primarily, still can't find a good reason why,
  Minix on Mac might use the same as I am, but it looks like it uses a movem to save %d0-%d2/%a0-%a1 instead of the weird order I
  have... this is kind of minor by comparison

- for the first question, I'm pretty sure linux saves all of %d0-%d5/%a0-%a2, which are all the syscall registers plus some (still
  don't know why %a2 specifically), but either way, every interrupt always saves those registers, so it doesn't try to be too fancy
  and have two ways of entering?  It looks like it.  That would certainly be easier
- ah, I have them in the slightly weird order they're in (%d0, %d1, %a0, %a1, %d2, %d3) based on the read and write syscalls, which
  (SYSCALL3) which takes an integer (%d1), and then a pointer and size (which is pointer-like).  Interestingly enough, I don't have
  any SYSCALL5's, even though I've defined it (and not 4).  Oh it's just not in unistd, but it's in socket.  And there it looks like
  it doesn't make much sense... "a" registers have int flags and the ints in %d2 and %d3 are the actual pointers

2025-03-16:

- Ohhh!  Linux is using a different kernel stack *for each task*.  That's why the context switch seemed a bit weird.  It pushes the
  basic registers to the kernel stack and I think it also keeps the exception frame on there as well.  That's why it doesn't seem to
  copy anything from the kernel stack to the user stack when switching tasks.  It just stores all the data on the kernel stack.
- I'm not sure why it's doing this yet (other than convenience, if you have lots of memory).  Unless there's a better reason, maybe
  I should avoid this to keep the memory usage down?
- what happens when a signal occurs?  I think that's the only weird case where you'd end up with 2 contexts on the user stack

- I'm kind of thinking, at least for now, I'll use only one kernel stack (per cpu, but only one cpu atm), and that kernel stack will
  always be in the ISP stack pointer, which is backwards compatible.  I won't make use of the MSP or the M bit for the time being.
- is it worth it to always switch the stack to the user stack, push the context, and then switch back to the same kernel stack and
  only push the rest of the context when switching, even though switching is probably going to be quite frequent.  Or should you
  push it to the kernel stack along with the exception frame, and copy it to the user stack when switching fully?
- or is it even best to push a0 to kernel stack, use it to push context to user stack, etc

2025-03-18:

- I think I will eventually move to a kernel stack per thread model, but for now I'll just do a single kernel thread and change
  things over more slowly.  I don't even have threads yet

2025-03-23:

- Making progress, but still don't have a working context switch that delays the switch until it's returning, and only switches if
  it's actually changing processes
- so a little while ago I figured out that there was an issue with returning from a syscall, and that was because the code that set
  that value is manipulating the context itself on the user stack.  This is a major point to note when changing the context layout.
  Previously, the register %d0 was at the top of the stack, but that's not the case now, if the extra regs are only pushed as
  needed.
- I caught this by make it do the full switch but using the new macros.  I had it working when the extra regs were pushed before the
  syscall regs, but not in the opposite direction.  Greping the code found places where proc->sp was being used, and that lead to
  finding the issue.  I moved that code to a function in syscall_entry.S so that it would be more obvious that that was happening.
  The code that actually set it was in schedule.c, so it's not supposed to know about the context format anyways
- the symptoms were that it would appear to hang when starting multitasking, but it was still context switching according to the LED

- I then tried to get the delayed switch working, and that's been a nightmare.  It usually gives a privillege violation, because the
  flags register ends up being 0 due to an invalid stack.  Using the moa emulator, I was able to figure out that (at least in some
  cases), it was doing the switch correctly the first few times, but not after that
- there is an issue with starting multitaskings since the context needs to not try to save the previous process, which is NULL.  I
  had some code to check if the previous_proc was null, but that was maybe causing more issues, so I disabled it, and that caused
  different issues
- one of the problems was that it was restoring the current_proc stack, and then saving the previous_proc stack, and not looking at
  the current_proc value again before popping, but if the check to see if the proc is the same is disabled, then it won't use the
  updated sp when popping current_proc, so for now I have it switch to current, switch to previous, and then switch back to current
- It was still having a bad switch somewhere, and moa with a breakpoint just before it starts the stack manipulation found that
  after 4 or so switches, it messes up, when trying to pop off a new stack.  The stack doesn't have the full context on it, so when
  the switching code does the swap, it pops the extra regs off the stack which aren't there and thus later on pops the wrong data
  during rte
- more grepping of the code didn't find the issue, because I didn't look at the code around it.  I tried setting a breakpoint on the
  signal code because that involved some stack manipulation, but that didn't get hit before the bad switch happened
- I can't quite remember how I clued into the process clone.  I might have been looking at new_proc and stuff, but somewhere along
  the line, I realized that the process cloning/fork was the problem.  It's cloning the current process which has an incomplete
  context on its stack, and so when it goes to actually switch procs, the new proc doesn't have the extra regs, only the syscall
  regs!
- fixing this made the privillege violation stop, so it's successfully switching, but it now hangs before the shell starts.  I
  *think* that might be because of the return value again.  I think the problem in general is that the context on the stack is not
  consistent.  If you're doing something with the stack of the current proc, then it's only got the syscall, and if you're doing
  something with any other process, it has the extended stack
- nope, trying to conditionally set the return value in the context doesn't fix the problem.  It seemed to instead make context
  switching halt.  When it's swapped from what it should be, it continues context switching and hangs before starting the shell

- ok so after a bunch of debugging, I realized that since the clone function is just subtracting some size for the extra registers
  (because it has no access to the extra registers that weren't saved before the syscall), they'll be all random values, and that's
  probably what's causing the emulator to jump to an address which is actually some instructions.  It almost works but won't work
  correctly unless those extra registers are actually cloned along with the rest of the process...
- So looking at linux, it has specific entry points for fork, clone, sigreturn, and a few others, which save the switch stack every
  time.  It feels a bit like cheating, because only "blessed" syscalls get the special treatment needed, but it's certainly more
  optimized/performant.

- This is the key point!  I'm pretty sure I knew this a few years ago too when I was looking at refactoring the context switch, but
  gave up at the time because it wasn't important then.  When using a switch that delays the full switch until necessary, you can't
  do it so casually.  You either need to have special entry points for the syscalls that could create a new task (or else the full
  state can't be cloned), or you need a way to delay the full clone/stack clone until exiting to a user process, so you can get the
  full state.  There's really no other way (besides always saving the full state or the non-recoverable state, MMU and FPU state
  could be delayed still, but integer regs state can't because of C and what it will do (ie. save regs as needed instead of putting
  them all in one place))

2025-03-28:

- looking at it more, I'm not sure how it actually uses those special entry points.  Oh I see, it's a table in assembly of entry
  points, which is the same as gloworm is doing but it C.  I could shave off a few instructions by not saving arguments on the stack
  but using the registers directly, and saving a jump instruction by putting the actual table call in assembly
- the special entry point would go in the syscall table (so jumps to C, the jumps back to the same entry file, and then back to a
  hard-coded syscall function in the same C syscall file as the jump.  Given that, it does kind of make more sense to move it to
  assembly.  There are those LED control calls in the C version, but actually I could make a syscall entry/exit hook with compiled
  in optional code like that, so it can be added or removed more easily with a kconfig setting

2025-03-30:

- I still haven't gotten back to this.  I had previously tried looking at linux's other archs to see the switching code, and I can't
  see that same trick that the m68k code has with redirecting the fork and clone syscalls.  I wonder if that was an older solution
  and the maintained archs have a newer better way of doing it, or if they're just really convoluted because they're more highly
  optimized
- I'm still thinking of doing the redirect solution.  The delayed clone might work too, and it would require less refactoring of the
  syscall code, but might be too complicated?  I guess you'd have to store a pointer to the new process, and check that pointer when
  returning to see if you need to complete the clone, and it would only work with a single clone/fork, even though that's likely
  all you'll ever need
- looking at the mips code, the fork/clone calls are wrapping in save_static_function, and there's a comment about that being
  replaced with SAVE_STATIC.  Etiher way, it seems that the same trick is in place to save some of the extended regs conditionally,
  but it's been made generic so any syscall  that needs it can access those values.  I don't really know how it works yet though

2025-04-08:

- I tried implementing the do_fork hook to save the regs before it actually clones the process.  I still have it using the
  do_syscall entry, but that should be ok because it's not using anything but the scratch registers during that, so the extra regs
  will still be preserved when it enters the new __do_fork.  That new entry saves the regs on the user stack of the current process,
  calls the normal entry (which doesn't take arguments anyways), clones the process, and returns to pop the extra registers again.
  I tried with both a sub instruction and a proper RESTORE, and both are causing a fatal exception, privillege violation, because
  it's popped the wrong value into the flags register and jumped to address 40, which is a MOVE to SR instruction.
- I have gotten this before, but I can't seem to find it in my notes.  I know it's because there's some kind of inconsistency in the
  user stack, but I haven't changed that as far as I can tell.  It should be working
- I inspected the stack of the process that failed (according to the stack trace) and couldn't find the expected flags value of
  0x2000.  On a hunch, I tried commenting out the set_proc_return_value function in the fork, since it will calculate the wrong
  address now, with the extra regs on the stack, and while it didn't work, it did at least avoid the fatal exception.  The LEDs are
  flashing to show it's context switching, but it's hanging, as it does
- I tried a hack where I change the value of current_proc, and it's still hanging, and only prints "forking 1" so it's not getting
  past the `init` process.  I feel like I'm close though


- I worked on this again tonight, and I've been going in circles of sorts, but still fixing issues in the process I think.  It
  either has a fatal error, or it hangs after the first fork, depending on what I change.  I thought it was just an issue with the
  return value, so I removed the explicit set function in the context, which needed to conditionally know where in the stack to
  store the return, and replaced it with a value in the proc struct that is set just before returning, but that uncovered a
  behaviour where it doesn't always set the return value, so I had check and reset the flag in the bits member of the proc struct
  when it sets the return value, and in the process removed a run check before setting, and then changed the logic of the bit to
  suit a bit better, and it's still fatal erroring
- I'm pretty sure the current issue is that it doesn't pop the extra registers for the process that is just starting after being
  cloned?  Well either way there's 9 extra long words on the stack (maybe 11 since the rte has already popped those off and caused
  the fatal to begin with).  So it seems like some other condition where it gets the logic wrong on whether to skip parts of the
  restore_context final work
- Ah! right!!! the problem is with exec.  I keep forgetting about exec.  Pretty sure I previously came across this, but this has
  been so drawn out over the last two months, I can't remember all the things I ran into.  I put a print statement on the syscall
  entry to trace what's going on, and it ends in EXECBUILTIN, which is probably trying to launch the shell.  The exec's context is
  probably wrong since it's actually the same current process, even though the executable is different.  create_context is wrong at
  least in this case

2025-04-09:

- I commented out the extra reg values in the create_context function so that when exec was called, and the current process was
  recreated, it would create a new short context so that it would restart properly, but that also fatal'd.  The syscalls were different
  though
- it was doing a bunch of syscall 4 (write), and then it does a syscall 3 (read) and fatals.  That's the first point where it would
  block.  So something else happens that breaks, possible the idle task or some other task that runs that doesn't have the right
  context.  I really need some way to know when creating the context if it's the current process or not
- I wonder if Linux has a similar thing, or if there's a higher level interface to the arch-specific context code, or if it doesn't
  need this difference for some other reason

- oh, just looking at RESTORE_ALL in linux's m68k arch, it's got two values on the stack that it pops off last.  One is the orig d0,
  and the other is a stack adjustment (according to the comment), but I don't yet know what value that is.  It's added to the
  existing stack pointer, so that makes me think it's inherently the size of the context.  It could be 0 if it's a full context and
  36 if it's a short context, and there's no conditional stuff.
- The same thing could be done with the d0 value, since it's comment is orig d0.  Store the value of d0 (in the struct process) when
  entering the context, and restore it when leaving.  That way you don't need flags.  You just restore whatever the value is, and
  it'll be updated with the syscall return if there is one.  That's much more efficient
- searching for the stack adjust value, and they're all clr instructions that set them, so it's not actually used in linux.  I
  wonder if it was used for the reason I'm thinking of using it, but it's been removed for some reason and is kept for legacy
  purposes, or it's expected of all architectures, and others use them but the m68k doesn't need it? *shrug*

2025-04-11:

- Ok I finally fixed the crashing, but it's still not getting to the shell.  I had to add a flag to create_context to selectively
  create an extended context or not.  When using exec on a proc that's the current proc, it will use an extended context, otherwise
  it won't.  That gets through both the initial process start (with the exceptional extended restore on first start), and also
  the initial switch to the idle task, which needs an extended context because it's not the first process run.  I think the
  remaining issue might be related to the return value still, which probably is still buggy
- the current approach is messy and fragile, so hopefully I can make it better by initializing the return d0 value when entering the
  kernel, and fixing the need for the extended context flag, or the exceptional case there.  Honestly, the easiest fix is of course
  to have two stacks per process, but I still want to avoid adding that just yet
- btw the issue I had with it not working last night was that the create context flag passed by C was a long word, so it was always
  using 0 instead of the actual extended flag value when creating the context, and always created a short context

2025-04-12:

- Today I'm going to consolidate the changes I've made that aren't related to the context, so I've got my changes stashed and
  re-applied so I have tho originals, and I've reverted the context changes and am adding back in the minimal changes needed to get
  the enter_exception and other non-asm changes working
- so far it's hanging with task switching working, so I'm pretty sure there's a problem with the return to user process and the
  return value itself, which makes sense.  The other changes to delay the full switch are probably working but the return value
  isn't which is causing the hanging behaviour I've been seeing in the full change

- I've spent all day trying to chase down why it's not working.  I'm not doing the delayed switch.  I went back to the first commit
  after main, 76c14006e0fd669b2b4aa3596a3ff12a8bbdde52, and that commit is broken for some reason, even though I thought it was
  working before I committed.  The syscall gets 0 as the number, so it prints the test message (syscall #0)
- the latest commit, f72add615976e9a5b021d3cc19b02ede7982ca76, fails for a different reason.  It seems to almost work but when it
  returns to the shell process, pid 3, the stack seems to be corrupted somehow.  My emulator doesn't behave the same way, but I've
  definitely got some bugs in the instructions, so not surprising.  It runs the init process alright, and I think it probably
  switches to the idle process at some point.  The init process does a fork syscall, and then waitpid, and when it should switch to
  the shell process, it either hangs or gives a format exception (stack format word is incorrect)

- hmm... when I reverted the changes to the proc struct, it started working enough to be switching tasks, but the return value is
  still likely wrong when the child fork returns because it's showing two waitpid calls (syscall#7), and then hangs, but the LED was
  flashing
- adding just the return value into the struct made it halt due to out of memory, so it's not happy with that
- moving the bits member makes the stack use 0xFFFFFFF7 as the size for some reason, which then makes it hang

- I don't know what's going on.  I fiddled with some things in the proc struct, and now it seems to be working with return_value up
  high.  I moved mem map to below the pid numbers and made the bits a uint32_t.  Not sure if there's a corruption issues somewhere

- alright, I have it working it seems.  It was of course the return value.  I finally got it to go in the proc struct, and I set it
  in the enter_syscall and enter_irq, and then always (instead of conditionally) set it on exit to user space, and that sort of
  worked but then it would go directly to the monitor as soon as a key was pressed...
- after a second of thinking, I figured it was probably the enter_irq, since that is re-entrant but I was storing it in the single
  process struct... so it was being overwritten.  The existing return code was complicated with the bit flag for a reason, because
  it's a tricky problem...
- moving the enter_irq d0 copy to the SAVE_CONTEXT macro, so it's only saved when entering from user mode, which only happens once.
  Otherwise it will do the normal kernel scratch registers entry.  I still have the syscall entry setting it to -1, but I think
  that's ok because it should always set that value anyways in the syscall handler code
- hmm... I wonder if that's why it was broken when I substituted the C version of the syscall handler... because I forgot to call
  the return_to_current_proc(ret) call

- well signal handling is definitely wrong.  I ran tcpserv and set up slattach and could send messages just fine, but when I did a
  ctrl-c on tcpserv, it went directly to the rom again.  So the signal handling stuff is wrong somehow, maybe still the return
  value... maybe it's actually the syscall set, if a signal happens
- nope, that didn't fix it, but there's no harm in removing it anyways

2025-04-13:

- another whole morning of fighting with it but I finally got the delayed switch working.  The idea of putting the context size on
  the stack, which can then be popped off, and checked before popping the rest.  It's much simpler than what I had before with
  trying to "know" what context is on the stack
- the main stumbling blocks that caused it to take so long were 1, the saving of the previous process was happening for kernel
  re-entries via the irq entry, as well as coming from user mode, which would overwrite the intended value
  2. the wrong stack was being used sometimes when resuming, which was caused by the code that compares the current and previous
  procs and skips the switch, but in doing so would skip past the setting of a0 and a1
  3. the wrong syscall was being done because the saving of the current_syscall pointer was happening after the context size was
  pushed onto the stack, so the syscall number was always the context size and not the actual value of d0

- now I just have this signal issue, where when a signal is sent and a custom handler is registered for that signal, it will jump
  straight to the rom instead of exiting the process.  It works fine for binaries that don't have a custom handler, but tcpserv
  specifically does, to test signals and socket cleanup (I think)
- there may be multiple issues, caused by the various changes, but the current one is caused by something that effects both the full
  regs switch and delayed switch code
- there could be an issue where the process that causes a signal to be sent to the same current process, the switch regs won't be
  available.  This would be solved with a kernel stack per task because it would be saved on the stack from entry into the signal
  dispatcher, so there's no need to save them at the start.  It's only because I'm trying to use the user stack, and practically
  throw the kernel stack contents away each user entry/exit pair.  I can only throw away those C-saved extra regs on the stack if
  they're already saved on the user stack, but the delay switch will never save them.  But that's not the straight to rom cause
- well that's interesting.  I put a printk into the syscall again to print which number was called, and now tcpserv is exiting
  properly now
- tcpserv actually sets the signal handler to NULL for some reason.  I guess overriding the default action?  But it still fails

2025-04-14:

- I thought the signal problem might be related to `previous_proc` being set, so I explicitly set it to NULL in close_proc but that
  didn't seem to change the jump to rom issue.  It's definitely happening after exit_proc though
- If I comment out the body of `exit_proc`, it works without crashing, so it's something related to the deallocation/free code there
- oddly enough, it seems to be related to release_fd_table, and not to the process memory itself.  Not sure why though
- I thought I was chasing it, but I had forgotten to save a file, so I was, infact, not
- ah interesting, it was not working still with the file->ops->close function commented out, but working with free_fileptr commented
  out, and when it worked, it complained of "double free on file pointer 3".  The explicit ops close happens on the previously freed
  file pointer, which might explain why it jumps straight to rom (calling a NULL address)
- change the call to only call close if refcount == 1 instead of <= 1 has at least fixed it so it doesn't crash, but does print out
  the double free error message

- so it's not a problem with the refcount being calculated wrong. It's a problem of the file pointer/table being incorrect, with a
  pointer to address 3 (totally invalid) and refcount in the -30720.  The table is all null when starting, and is corrupt when
  exiting
- ah I missed some functions, it's defintely a set_fd call that causes it
- Ok, I found the cause.  It's setting it to 3 when exiting from the accept system call after blocking and suspending the current
  system call, since nothing has connected.  This is literally the only place in the code that uses suspend_current_syscall() that
  has anything other than a return after the suspend happens deeper in the code.  Every other suspend returns 0, and every parent
  call just returns the result.  The accept() syscall is the only one that checks for an error code (< -1) and then sets the file
  pointer and returns.  I don't know if the other calls like connect() should also return -1 if there's an error, or just generally
  what's the best way to solve this in a way that's regularized for future calls
- also, this is defintely not a new problem.  I probably even found it a while ago, but maybe didn't look into it at the time
- I decided to go a bit defensive, since it is the kernel, and set NULL both before calling functions that take a double pointer,
  and also set the result to NULL when exiting from net_socket_accept() due to a suspend

2025-04-18:

- I keep debating whether to go with two stacks per thread, and I feel like the path forward either way will be complicated so I
  should decide now rather than deferring.  I'm also thinking, when using user mode which I'm not using at the moment, the exception
  frame will be on the kernel stack.  The only reason that doesn't happen now is because the supervisor stack on an interrupt is
  the user stack
- if user mode is not configured, it would only use one stack, but if using user mode, then it uses two stacks.  That should be
  easier to implement
- since I'm targetting homebrew systems mostly, I should definitely stick with monolithic instead of microkernel.  Microkernels are
  neat, but more complicated to get working and have more overhead as well, so a monolithic would be easier to port

2025-04-19:

- for a while now I've been chasing this last bug where when I activated the `request_irq` table call in `do_irq`, it would hang at
  some point because it had the wrong irq number.  I kept thinking it was a problem with getting the right irq number from the
  stack, but no... it turns out I just had the wrong function set by the tty driver *facepalm*.  It was going to enter_irq, which is
  what it set the direct vector table to in order to make the hardcoded version work, but it needed to be changed to calling
  `handle_serial_irq`.  Now it works and get the right irq number every time...

- I now have a fully working full context switch committed, and a working minimal patch for delayed context switching.  *phew*  Now
  I don't know which one I want to use
- I'm now strongly thinking of use two stacks per thread, when using user mode, and when not using user mode like it does now, it
  can use only one stack since that's all it needs, and I think it should be relatively minimal to change the existing context
  switch to suit both (ie. the user mode version basically just doesn't switch stacks in most places, where the non-user mode
  version switches like the existing ifndefs use)
- but I should probably add threads and a page allocator first?  I guess threads still aren't that important so I can leave them,
  but I could at least start making room for them

2025-04-20:

- I've started implementing the page allocator and virtual memory/mmu although it's still very early.  I have a page allocator using
  bitmaps but it needs testing (doesn't work yet), and I haven't done much about the mmu
- I've put the Kconfig stuff in arch which is where linux puts it since it's platform dependent, but the global CONFIG_MMU flag is
  defined in each architecture that implements it.  I keep thinking in a very type theory oriented way, where each flag must be
  globally defined and then selected by different archs, but I need to get over that
- I have the same reaction to the parts of the code that call into arch/ code.  I've taken to at least prepending the `arch_` mangle
  but I haven't defined them in a common location in include/kernel/.  I feel like I should defined a common interface and not just
  copy mistakes from other operating systems

- also it turns out Kconfig has the option of conditional defaults, `default <value> if <condition>`


2025-04-22:
- Using page memory for the bitmap doesn't make much sense in some cases.  It's copied from ruxpin which allocated 256 MiB of RAM
  which requires 2 pages of memory for the bitmaps, or 8192 bytes. For a system with 1 MiB, it's 32 bytes of bitmaps, 4064 bytes
  unused, and only 8 *bytes* of memory for a 64KiB block, which too, keep in mind there, will be multiple blocks rather than one
  big block that covers all of RAM


2025-04-24:

- I have the page allocator working, both contiguous and single, but I think I still have an off by one page error, because it
  allocates 0x208000 when it should stop at 0x207000


2025-04-26:

- I think I have paging working, and I have the start of a testing framework for unit tests that run on the host.  I need to make it
  able to compile for m68k as well, so I can run tests there instead of putting them in monitor.bin


2025-04-30:

- there's a problem with the lib .a rule, which is needed to build a library but if no dependencies are supplied, it won't decend,
  and instead make an empty library that needs to be cleaned before it will even attempt to recompile the lib.  This is a problem
  when compiling bare-tests from a clean repository, where libc won't be compiled and it will fail during linking
- I ended up making the test include really only contain the rules for tests, and put the variable resolution stuff into
  Makefile.build, because the prefix-adding lines in the build file needed to come after the test variable filter/substitute lines,
  but not that I think about it, I could just put the test rules above all the variables


2025-05-05:

- looking at the options for page sizes, and how to set initial shift (IS), the TIA/TIB/TIC/TID fields, and page size.  The manual
  says they must all add up to 32.  There is also a function code option not shown here, where you can have up to 3 extra bits that
  make up the function code used like an address space expansion.  That's not really an option on some hardware, such as the k30p
  because it uses the function codes to change the address modifier bits of the bus

- that leaves these combinations, if you have one entire page used as each table.  It would be possible to make one or more levels
  be multiple pages, or less than a page in order to make it work without the initial shift, but if each page table level was the
  same size, filling exactly one page:

fn main() {
    for page_bits in 8..16 {
        let remain = 32 - page_bits;
        println!("with  long descriptors, initial shift: {}, levels: {}, table entries: {}, page: {}", remain % (page_bits - 3), remain / (page_bits - 3), 2_u32.pow(page_bits - 3), page_bits);  
        println!("with short descriptors, initial shift: {}, levels: {}, table entries: {}, page: {}", remain % (page_bits - 2), remain / (page_bits - 2), 2_u32.pow(page_bits - 2), page_bits);
    }
}

with  long descriptors, initial shift: 4, levels: 4, table entries: 32, page: 8
with short descriptors, initial shift: 0, levels: 4, table entries: 64, page: 8
with  long descriptors, initial shift: 5, levels: 3, table entries: 64, page: 9
with short descriptors, initial shift: 2, levels: 3, table entries: 128, page: 9
with  long descriptors, initial shift: 1, levels: 3, table entries: 128, page: 10
with short descriptors, initial shift: 6, levels: 2, table entries: 256, page: 10
with  long descriptors, initial shift: 5, levels: 2, table entries: 256, page: 11
with short descriptors, initial shift: 3, levels: 2, table entries: 512, page: 11
with  long descriptors, initial shift: 2, levels: 2, table entries: 512, page: 12
with short descriptors, initial shift: 0, levels: 2, table entries: 1024, page: 12
with  long descriptors, initial shift: 9, levels: 1, table entries: 1024, page: 13
with short descriptors, initial shift: 8, levels: 1, table entries: 2048, page: 13
with  long descriptors, initial shift: 7, levels: 1, table entries: 2048, page: 14
with short descriptors, initial shift: 6, levels: 1, table entries: 4096, page: 14
with  long descriptors, initial shift: 5, levels: 1, table entries: 4096, page: 15
with short descriptors, initial shift: 4, levels: 1, table entries: 8192, page: 15

- there are only two that work evenly, and they're both only possible with the short descriptor, 256 byte pages and 4kb pages
- the long descriptor 1 level 8k page size would use 512 entries of the 1024 top level page, so adding an extra level would not
  waste too much memory
- the top level page could even be split between the page table and other memory information that a process might need
- I'm not sure if i should only support two page sizes for now, or make it possible to sacrifice address space optionally


2025-05-19:

- haven't had much time to work on this with the house hunting and closing the deal on the new place

- I've got a mapping function working.  Starting it was the hardest part tbh.  I'm still not sure if I should put everything into
  that one function, or have a separate unmapping function, at least for the total unmapping (freeing the page table pages
  themselves)
- the trickiest part of unmapping is knowing whether to free a page or not.  With ruxpin, since it's aarch64, and there are some
  extra bits available to the user in the page descriptor, I used one of those bits as the copy-on-write indicator, and if it wasn't
  set, that also means the page is not shared and should be freed, but if I'm using short descriptors on 68k (which are the only
  ones that work out evenly for 4k and 256 byte pages), I don't have those extra bits to store in each descriptor.  It looks like
  x86 is the same, not having user-defined bits
- Given the above, I think it's better to find a way to do this without storing bits in the descriptors, so how do I know if a page
  is shared or not?

- thinking about adding the mmu table to the process, and it should be context because it's arch specific and loaded during a
  context switch, but now that I dig into it, since context is used by signal handlers as well, which don't need to change the root
  table, it seems to not fit to put the table there...
- maybe there needs to be two halves to this


2025-05-20:

- was just laying in bed and thought, for the copy on write bit, you could set the WP (write protect) bit in each descriptor, and
  have the segment it belongs to be marked as read/write, so when you get an exception when that segment is written to, it can check
  both bits to know that copy on write is set, but that particular page has not yet been copied, and copy it before resuming

- I have the `clone` syscall piped through, with a test program `threadtest`.  I just need to actually differential clone from fork.
- I don't need to rename `process` yet
- part of the clone/fork implementation is in clone_process_memory, but some is also in new_proc, namely the pid related stuff...
- the stack init part of clone_process_memory is only needed in fork, and not clone
- is there a bug where the heap isn't cloned properly, only the stack?  It probably wouldn't be noticed much since most things call
  exec() right after forking


2025-05-27:

- I broke through the block I was having by deciding that I can use kmalloc, and I'll eventually fix kmalloc to use pages, if it
  mostly allocates small things.  The pages don't have to be contiguous
- so then I was able to alloc the memory_map and memory_area structs, and construct the address space like that.  I only need to
  make the entire map shareable, and not the segments.  The file is already shareable, and accessing its blocks will always return
  the same page memory holding the cached data, which can be directly added to an MMU map with copy on write set, or if no MMU, it
  would be copied into the contiguous memory block of the process
- I'm kind of bogged down again in fixing the mess of switching from an array of pointers to a queue of private structs, and
  breaking all the code that sets up the process's memory.  That code is going to need to be partly architecture specific


2025-05-28:

- I should be able to abstract the actual adjustment functions in a way that's generic, so I'll have a library for manipulating
  segments and such, but what part of the whole process should be arch-specific?
- what should be arch-specific and what should be mmu vs no-mmu?

- I'm getting close to something testable, but I still have a few areas to patch up, and it's still broken, but I'm trying to make
  it work again before changing more about how the process's memory is initialized
- once I'm done that, I'll still only have no-MMU support, and I'll have to add that and somehow change the code in
  clone_process_memory, where it kmalloc's a new stack.  That will have to include the code, but also, when using an MMU it will not
  kmalloc at all, and rely on the memory_ops and page faults to load or allocate everything

- should I introduce something like FreeBSD, which has a vm_object for the thing that backs the memory area?  Linux just has some
  hardcoded values instead of a separate abstraction.  Should it be allocated and refcounted?


2025-05-29:

- Oh I see why the data segment was initialized to 0, and the stack to everything, and that somehow wasn't glaringly broken.  It's
  because all the data segments are loaded into the code segment.  That also means the data and bss segments would work without an
  error since they're the correct offset from the code, and the heap doesn't need to be anywhere specific.  It's just really
  confusing to me to do that
- maybe I could make the heap its own segment, so that it's clear it's distinct from data

- I have it almost working, but I forgot to add the code to create the map itself, which isn't done automatically in case the
  process is cloning the memory map of another process


2025-05-30:

- now that I think about it, if you just copy the stack, the pointers will all point to the old code segment.  I'm pretty sure I've
  come across this before, just haven't looked for any existing notes yet.  It mostly works because exec will be called shortly
  after on the child process.  The code itself will still use pcrel but any relocation table updates would have to be redone, and
  any addresses on the stack or in registers would be invalid


2025-05-31:

- just to remind myself, the reason I didn't put a refcount in for the memory address space in ruxpin (and why one doesn't exist in
  linux I think), is because it can changing the address space, and just set copy on write on all the existing pages.  The address
  space refcount is enough.  But without the MMU, you can't intercept a write operation so you need to copy at least the stack ahead
  of time
- on 8086, you can duplicate all memory and change the segment registers to point to the new area, and all the addresses on the
  stack (assuming they aren't changing the segment registers) will still work correct while pointing at the duplicated memory
- for m68k, this isn't the case, and your stack, even though duplicated, will have addresses on the stack that return to code in the
  old process's space.  There could also be pointers that point to the old stack, if they were passed as arguments, which could
  definitely cause problems
- the short of it is that on m68k, it's just not really possible to fork a process unless that process almost immediately calls exec
- but this is the case where I acutally need some kind of alternate means of refcounting the backing memory, since what I'm doing to
  make the problem less problematic, is copy the heap/stack but make a ref to the existing code/data, and that's currently what's
  causing the double free issue I'm running into

- the code/data memory is freed twice because it just copies the addresses to a brand new memory_area
- I can refcount the memory_object, but then I'd have to allocate it as well.  So there'd be memory_map, memory_area, and
  memory_object, all wasting 8 bytes each to hold the alloc info
- I can't insert the same memory_area into the linked list in two maps, but I can go back to the array of pointers style list.  I'd
  have to realloc the area though, or else alloc the array separately, to allow the map to grow, so... I guess I still have 3 allocs

- oh right, now I remember how it was with ruxpin.  The pages themselves are the cached open executable file, so at least for those
  pages, they don't need to track the refs, as long as the file handle/vnode ref is held.  Unfortunately, that trick only works with
  an MMU, so non-MMU mode will have to behave differently, and that difference needs to be easy to make configurable

- now, unrelatedly, I'm thinking maybe the notation of `clone` is not good when it's always refcounted by meaning, and sometimes I
  need some other kind of `duplicate` function... so how about `memory_object_ref` or `memory_object_make_ref` or get_ref, or...


2025-06-03:

- I'm pushed into using 3 allocations, and generally such a complicated memory map solution, by the no-MMU m68k architecture.  It
  also requires a fairly unique memory map, as would the no-MMU 8086 arch.  I'm struggling with  how best to isolate the process
  creation code for each arch


2025-06-08:

- I've made a new file, exec.c, in addition to binaries.c, fork.c, and init.c.  I've pushed the reset_stack stuff into exec.c and
  the reset stack call into binaries.c for now.  My intention at least, is to put the common exec stuff into exec.c and try to keep
  init.c as small as possible, so all the memory related creation is done in exec.c, and can be changed once without having to
  consider both so often.  fork.c will have process forking/copying which is quite different from new executions.  And eventually
  some of what's in binaries.c, the common non-file-related parts can also be pushed into exec.c so it has all the common new process
  initialization code
- also, I have a bunch of memory leak issues with memory map, and objects, where the refcounts are wrong and the process memory,
  which is kmalloc'd at the moment, never gets freed


2025-06-10:

- I mentioned the issue of forking a process on 68k in the Usagi Electric - Homebrew Computing discord and PenguinOfEvil (the
  creator of Fuzix) responded:
      You copy it back when you task switch. That's how Fuzix works, it's how Minix works on 68K. There's only one generic old era
      small Unix program commonly used that forks and doesn't then exec something which means no more copying needed - that's kermit
- I was looking at Minix last night, and I found it has an extra shadow value in the proc struct with the memory map tables, and it
  delays the copying until the kernel (and not the mm process) handles the fork, at which point it does a copy.  Last night I was
  thinking it was just one copy, and it looks like just one copy, but Penguin is alluding to it copying the shadow region into the
  same working region (primarily the data segment from the looks of it) on every task switch?  I can see why that would be slow, as
  he mentioned much earlier
- I feel like I've had this conversation with him before, but I remember it only vaguely.  Generally this solution is called the
  shadow solution or shadowing, and there's a special shadow.c file just for it in the Macintosh Minix source code that I have
- the Minix code mentions 500ms as the FLIPWAIT time.  It seems to be doing the copying itself in the clock code and not the context
  switching code.  I'm not sure what's up with that.  It does seem like a weird implementation of the concept, or just difficult to
  follow
- The last time I heard of this, I had probably decided not to implement it, and I'm kind of thinking the same thing this time,
  since almost all procs will call exec() after a fork(), but it would be nice if the new refactor would make it possible to
  implement later
- that said, now that I'm thinking about memory usage and constrained systems, I'm starting to second guess the approach I'm taking,
  with so many allocations.  Maybe I should try to simplify it a bit?  It's a tradeoff between flexibility for larger systems and
  memory usage for smaller systems, so in that sense, it's maybe better to focus on larger systems, but I still feel bad about it.
  Maybe I could make some of it compile-time selectable?

- from the todo file:  after looking at linux code, it initializes a new mm_struct when loading the binary, and then swaps it in
  into the process when it executes, which is a much better way to do it, now that I have a separate alloc for the map itself

- I've cleaned up the map and segment allocating code, with init.c using exec.c to launch new processes, and both kernel execution
  and elf binary from fs works and runs correctly enough to not blatanly fail.  The increment and decrement messages are being
  printed, so that's a big one to fix still.  I don't have that in my todo list yet


2025-06-14:

- I was making this pretty complicated, but realized that if I switch to the pages system instead of kmalloc for user memory, I
  wouldn't need to free the block at once and could instead have it free the single block as multiple blocks (so that the heap and
  stack segments could be free separately).  That means when cloning the process, it doesn't need to ensure it only copies one
  memory_object as the heap/stack
- now that I write that though, I realize that not only am I probably not adjusting the cloned heap correctly, but I'm also probably
  not ensuring that when the heap grows, it only grows by PAGE_SIZE increments


2025-06-19:

- I was thinking that maybe I could eliminate the memory_object by forcing adjacent kmalloced data to be allocated separately, but
  then I remembered that that would mean the node tracking data would be between segments, causing the addresses to be all wrong,
  for an elf file, so that doesn't work
- I don't think it's possible to make kmalloc'd non-paged memory work without significantly more complexity
- if I go all in on pages for user memory in every situation, and I can always free arbitrary pages, can I simplify things more?  I
  could allocate contiguously and then break it up, but if I want to ever ^^^^ reuse pages without an MMU ^^^^ I need to keep track
  of how many things hold the pages still
- I can do that on a page-by-page basis like I did in ruxpin, or I can do that with memory_object

- I guess it's actually a waste of memory to use per-page refcounts without an MMU since the same page can't be mapped into a
  processe's address space on a per-page basis.  It can be mapped on a per-region basis (so all pages in a range)


2025-06-20:

- I feel like I have more code now, and I do in terms of creating memory maps and segments, but it seems like some of that is
  duplicate.  Not only that, but some can be reduced by removing it when using an MMU, or simplifying the memory map.

- I could possible go back to an array of segments structs (not pointers to structs), but then it's cumbersome to move them around
  if you want to insert a new one.  For non-MMU, that will rarely ever happen, but if you can use mmap, then it would happen more
  often, whenever using mmap, which would certainly need to insert into the middle where the heap is


2025-06-21:

- not that I'm unhappy with the current massive commit that I'm about to make, but I feel pretty conflicted about the memory
  segment/map changes.  I know it can do with a lot of massaging, but it's probably better to get it in and then change it after.  I
  should probably start making branches and then merging those branches without squashing which means I can commit without waiting
  so long, and still avoid main getting broken.  I certainly could have used diffs a couple times during this massive change

- I should change the memory stuff to not deal with segments directly but deal with mapping and unmapping addresses, and let the
  impl handle the rest


2025-06-24:

- even in no-MMU I can still have mmap support.  There's just nothing in hardware stopping accessing the memory without mapping it
  first.  As such, you can actually implement vnode bufcache paging things, so that it uses the same pages for all processes that
  access the same read-only data, so long as the address it's mapping to is NULL or can otherwise be changed by the OS.  I fixed
  mapping would still fail


2025-06-27:

- alright, I have mmap and unmap in the process memory code, minus the actual MMU stuff.
- I'm still thinking of how I could get rid of memory_object (possibly by splitting them when dividing memory?  I only want to use
  them as a per-region refcount instead of having to maintain per-page refcounts which would take like 4KB or more for 1MB of 256
  byte pages)
- I feel like I should get rid of the resize code as well, and use the mmap/unmap code instead, but maybe that's not so important
- I still have more to do with the memory code, specifically adding and testing the MMU table mapping, and separating the no-MMU
  cloning code and platform-specific cloning code from the MMU cloning, but maybe I should work on the context instead
- for the context, I need to merge the previous change that delays the full switch until later, and also add in the user mode
  support which is going to uncover a bunch of bugs.  I can't have a separate MMU table without adding that to the context switch,
  and I can't add that until the CPU switching works, but I would also need to add two-stack support and so on, so it will be a big
  change before I can get back to MMU support again


2025-06-29:

- I was about to dive into adding the second kernel stack in user mode, but instead I've been investigating why signals don't work
  properly anymore, since it's related to the context changes I've made
- programs like the shell which register a custom signal handler for SIGINT will have that handler run, but then exit afterwards,
  and it's acutally calling the exit syscall via `_exit` in the syscall_entry.S file, which makes me think the stack is somehow
  getting corrupted.  It calls _sigreturn, and then _exit right after, so it's likely a problem in the cleanup code
- the problem was introduced somewhere during the context refactoring, but I couldn't pinpoint exactly where because there are a
  bunch of broken commits in there
- disabling the special __do_sigreturn alternate entry point doesn't change anything, so I don't think this is related to that
- it's not strictly related to the delayed context switch that I just enabled recently.  It's related to the earlier context
  refactoring
- the stack pointer seems to be the same before the custom handler is called, and after sigreturn cleans up afterwards, which is
  throwing me off.  It should be right!  There must be something else, something subtle, going on
- that said, between when the handler returns and when sigreturn is called the stack pointer is different, but also when sigreturn
  is run, the process is the current process whereas when the signal is first run, it's not necessarily the current process that
  handles the signal.  I wonder if even sending a signal to a background task would work where the current process doesn't


2025-07-03:

- I had been banging my head on this problem for a while, where it wouldn't start, fork wouldn't work.  I had it working when
  user mode was disabled, and the changes when it is enabled are small, but it wasn't working.  It would call syscall 5, then 4,
  then 1 (which is exit) and then stop
- I thought it was something to do with the stack or the _exit return address on the stack, but it was actually the address of the
  `stop` instruction after the `trap` instruction in the `_exit` syscall, so it actually called the exit syscall for some reason
- just this morning I looked at it again and thought to check the syscall_entry.S file because it's the only place other than the
  stuff inside the CONFIG_USER_MODE blocks that might be affected by the few things changed by the ifdef blocks, and also at struct
  process, and then saw that the return_value field is after the task_info struct which adds the kernel_start field when user mode
  is enabled, so that explains why it wasn't working.  The return value was incorrect for the first syscall, which is fork, so it
  thought it was the child process and ran the utility and exited like normal!
- when I fixed the order, it wasn't working still.  It would run the shell but then crash on startup.  I started looking into it
  (around 8pm, after work), and recompiled fresh with the shell compiled into the kernel, and now it just seems to be working fine
  now, so maybe it needed a clean and make?
- nope, it's broken when it doesn't have the shell compiled in.  It forks the shell, runs /etc/rc, and then has some kind of
  exception.  Perhaps this is actually a privillege violation or something, and it's not displaying right (status: 7B72, vector: 19A)

- I changed `ls` to use a `stop` instruction, which should cause an exception if it's actually in user mode.  That instruction is
  privilleged.  When I tested it though, it gave a weird status and vector number.  Maybe it's using the wrong stack or something
  because it seems to be displaying wrong with other exceptions too

- yeah something's not quite right.  It's getting better, but it's not fully working
- threadtest is unable to write usp and then gets out of memory and dies


2025-07-04:

- so the threadtest issues was caused by sbrk, which used arch_get_user_stackp(), which wasn't implemented when a short context was
  on the stack and was returning 0, so I refactored to compare if it's the current proc that's changing its stack, and return the
  value from usp itself, and that's working now.  Threads are working again
- the signal problem was caused by not using the user stack, and putting the _sigreturn return address onto the kernel stack.  I've
  split that now, like the process context, but haven't tested yet

- using init on disk isn't working, but it's because of ntpdate from the looks of it.  It is returning from printing "timeout",
  which is delivered via a signal, but there's an extra word on the stack, or the address is just wrong on the stack.  It should be
  calling sigreturn there
- I had just forgotten to change the get/set stackp calls for setting _sigreturn, so it was getting/setting the kernel stack, and
  also not updating it because it used ksp to set instead of usp
- but it's still not working...

- in either case, the problem is handling custom signals.  Everything else appears to work, although I haven't tested extensively

